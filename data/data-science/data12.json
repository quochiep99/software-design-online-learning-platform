{
    "field": {
        "name": "data-science",
        "courses": []
    },
    "course": {
        "title": "Apache Spark with Scala - Hands On with Big Data!",
        "subtitle": "Apache Spark tutorial with 20+ hands-on examples of analyzing large data sets, on your desktop or on Hadoop with Scala!",
        "descriptions": [],
        "reviews": [],
        "students": [],
        "image1xURL": "https://img-b.udemycdn.com/course/240x135/892806_514e_3.jpg",
        "image2xURL": "https://img-b.udemycdn.com/course/480x270/892806_514e_3.jpg",
        "image3xURL": "https://img-b.udemycdn.com/course/750x422/892806_514e_3.jpg",
        "discountPrice": 11.99,
        "originalPrice": 129.99,
        "numViews": 0,
        "curriculum": []
    },
    "reviews": [
        {
            "body": "This course does not pay attention to details, concepts are explained in a very superficial way.",
            "rating": 1
        },
        {
            "body": "Fabulous and Amazing course. One should really take this course, if he/she is serious in learning spark3 by doing hands on examples.\n\nI personally had a great experience while working out every example myself, searching the internet how can I make the particular case work.\n\nIf one is honest with himself, he/she can learn a lot from this course.",
            "rating": 5
        },
        {
            "body": "It was a perfect course for starting Spark in a hands-on manner! Lots of interesting examples, course structure is prepared and presented quite well.",
            "rating": 5
        },
        {
            "body": "I knew very little about Scala before starting this course, but I'm certain I'll be using Scala and DataSets going forward. There are many hidden gems in this course that aren't overtly obvious when reading the docs on various sites: import spark.implicits._, use of case classes, and the transition from context, session to DataSets. As I spend most of my days in a terminal, I was particularly happy to see SBT and spark-submit explained so well. I've already written a few small apps that do fairly simple counts (on large DataSets) that use most of the features discussed in the earlier sections. It's interesting how one can transition from Spark to a bit of Scala, throw in some Java, then back to Spark for a result. In any case, I'll be taking the Python Spark course and additional Scala courses this author for sure. I'll also burn some calories on Spark Streaming with Structured Data as I can huge benefits for that type of implementation. Thanks for a great course, and I look forward to the next one.",
            "rating": 5
        },
        {
            "body": "The course is great for starters. I found the pace to be little quick but good to start with Spark.",
            "rating": 4.5
        },
        {
            "body": "I would have liked the course to be a bit more in depth. At one point the examples wouldn't work because of eclipse, after transitioning to intellij everything runs smoothly but struggling with eclipse frustrated me quite a bit. Some explanations were a bit too vague, I had to research on my own what some of the code does because of that.",
            "rating": 4
        },
        {
            "body": "Great course for someone coming in with a general knowledge of development but no experience with Spark or Scala. The examples are good, well explained, and offered in various ways to show you how to explore the problem as opposed to simply solving it. Highly recommend.",
            "rating": 5
        },
        {
            "body": "Only the first chapters parts are good. The latter topics are not explained in detail. This course simply gave me enough fundamentals to be able to understand more advanced Spark documents/courses.\n\nMaybe the author can watch Stephen Grider's courses to see how detailed he is in explaining things. Stephen Grider takes the time to create diagrams to make things easier to understand.",
            "rating": 2.5
        },
        {
            "body": "This course is pretty good. But it seems they have not updated it since long.. There are a lot less stuff on DataFrame and DataSets...Majory of the course is based on RDDs.\n\nUpgrade your course with the same examples solved with Dataframes/Datasets.",
            "rating": 3.5
        },
        {
            "body": "This was a great course, Frank explains very well all topics and source code, in some cases line by line, that's was awesome. I recommend a lot this course to starting with spark and scala.",
            "rating": 5
        },
        {
            "body": "A good course and very well organised. It covers all topics regarding Apache Spark. Thumbs up for the course materials.",
            "rating": 5
        },
        {
            "body": "This is the first Udemy course I've ever taken and I couldn't be more happy with this choice.\n\nFrank Kane is an excellent teacher, I totally recommend this course for beginners with a little bit of background in both programming and Data Science.\n\nJust in case my situation helps as a reference: I'm a mathematician who has been working as a data scientist for a year who has background with Python and SQL. I read a book of Scala before this course but I think for most people the Scala crash course included will be more than enough.\n\nRegarding the OS: the course is based in Windows but it's perfectly accesible if you're using macOS.\n\nRegarding the language: my mother tongue is Spanish although I've always enjoyed speaking English. I believe that this course is really accesible since it has subtitles and even a transcript.\n\nHope you enjoy this course as much as I do :)\n\nHappy learning!",
            "rating": 5
        }
    ],
    "students": [
        {
            "name": "Francesco Arnò",
            "email": "francescoarnò@gmail.com",
            "password": "francescoarnò",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Divyam Pandey",
            "email": "divyampandey@gmail.com",
            "password": "divyampandey",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Ercüment Ekentok",
            "email": "ercümentekentok@gmail.com",
            "password": "ercümentekentok",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Gregory A Beam",
            "email": "gregoryabeam@gmail.com",
            "password": "gregoryabeam",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Siddharth Ghosh",
            "email": "siddharthghosh@gmail.com",
            "password": "siddharthghosh",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Teodor Halvadzhiev",
            "email": "teodorhalvadzhiev@gmail.com",
            "password": "teodorhalvadzhiev",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Neil Newman",
            "email": "neilnewman@gmail.com",
            "password": "neilnewman",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Raymond Ong",
            "email": "raymondong@gmail.com",
            "password": "raymondong",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Siraj",
            "email": "siraj@gmail.com",
            "password": "siraj",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Adrián Ávila Olmos",
            "email": "adriánávilaolmos@gmail.com",
            "password": "adriánávilaolmos",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Robert Gabriel",
            "email": "robertgabriel@gmail.com",
            "password": "robertgabriel",
            "role": "s",
            "isConfirmed": true
        },
        {
            "name": "Álvaro Martín Jiménez",
            "email": "álvaromartínjiménez@gmail.com",
            "password": "álvaromartínjiménez",
            "role": "s",
            "isConfirmed": true
        }
    ],
    "instructor": {
        "name": "Sundog Education by Frank Kane",
        "email": "sundogeducationbyfrankkane@gmail.com",
        "password": "sundogeducationbyfrankkane",
        "role": "i",
        "briefIntroduction": "<p>Sundog Education's mission is to make highly valuable career skills in <strong>big data, data science, and machine learning</strong> accessible to everyone in the world. Our consortium of expert instructors shares our knowledge in these emerging fields with you, at prices anyone can afford.&nbsp;</p><p>Sundog Education is led by Frank Kane and owned by Frank's company, Sundog Software LLC.&nbsp;Frank spent 9 years at <strong>Amazon</strong> and <strong>IMDb</strong>, developing and managing the technology that automatically delivers product and movie recommendations to hundreds of millions of customers, all the time. Frank holds <strong>17 issued patents</strong> in the fields of <strong>distributed computing</strong>, <strong>data mining</strong>, and <strong>machine learning</strong>. In 2012, Frank left to start his own successful company, Sundog Software, which focuses on virtual reality environment technology, and teaching others about big data analysis.</p><p><strong>Due to our volume of students we are unable to respond to private messages; please post your questions within the Q&amp;A of your course. Thanks for understanding.</strong></p>",
        "isConfirmed": true
    },
    "curriculum": [
        {
            "sectionName": "Getting Started",
            "unitNames": [
                "Udemy 101: Getting the Most From This Course",
                "Introduction, and installing the course materials, IntelliJ, and Scala",
                "Introduction to Apache Spark",
                "Spark Basics",
                "What's New in Spark 3?"
            ]
        },
        {
            "sectionName": "Scala Crash Course [Optional]",
            "unitNames": [
                "[Activity] Scala Basics",
                "[Exercise] Flow Control in Scala",
                "[Exercise] Functions in Scala",
                "[Exercise] Data Structures in Scala"
            ]
        },
        {
            "sectionName": "Using Resilient Distributed Datasets (RDDs)",
            "unitNames": [
                "The Resilient Distributed Dataset",
                "Ratings Histogram Example",
                "Spark Internals",
                "Key / Value RDD's, and the Average Friends by Age example",
                "[Activity] Running the Average Friends by Age Example",
                "Filtering RDD's, and the Minimum Temperature by Location Example",
                "[Activity] Running the Minimum Temperature Example, and Modifying it for Maximum",
                "[Activity] Counting Word Occurrences using Flatmap()",
                "[Activity] Improving the Word Count Script with Regular Expressions",
                "[Activity] Sorting the Word Count Results",
                "[Exercise] Find the Total Amount Spent by Customer",
                "[Exercise] Check your Results, and Sort Them by Total Amount Spent",
                "Check Your Results and Implementation Against Mine"
            ]
        },
        {
            "sectionName": "SparkSQL, DataFrames, and DataSets",
            "unitNames": [
                "Introduction to SparkSQL",
                "[Activity] Using SparkSQL",
                "[Activity] Using DataSets",
                "[Exercise] Implement the \"Friends by Age\" example using DataSets",
                "Exercise Solution: Friends by Age, with Datasets.",
                "[Activity] Word Count example, using Datasets",
                "[Activity] Revisiting the Minimum Temperature example, with Datasets",
                "[Exercise] Implement the \"Total Spent by Customer\" problem with Datasets",
                "Exercise Solution: Total Spent by Customer with Datasets"
            ]
        },
        {
            "sectionName": "Advanced Examples of Spark Programs",
            "unitNames": [
                "[Activity] Find the Most Popular Movie",
                "[Activity] Use Broadcast Variables to Display Movie Names",
                "[Activity] Find the Most Popular Superhero in a Social Graph",
                "[Exercise] Find the Most Obscure Superheroes",
                "Exercise Solution: Find the Most Obscure Superheroes",
                "Superhero Degrees of Separation: Introducing Breadth-First Search",
                "Superhero Degrees of Separation: Accumulators, and Implementing BFS in Spark",
                "[Activity] Superhero Degrees of Separation: Review the code, and run it!",
                "Item-Based Collaborative Filtering in Spark, cache(), and persist()",
                "[Activity] Running the Similar Movies Script using Spark's Cluster Manager",
                "[Exercise] Improve the Quality of Similar Movies"
            ]
        },
        {
            "sectionName": "Running Spark on a Cluster",
            "unitNames": [
                "[Activity] Using spark-submit to run Spark driver scripts",
                "[Activity] Packaging driver scripts with SBT",
                "[Exercise] Package a Script with SBT and Run it Locally with spark-submit",
                "Exercise solution: Using SBT and spark-submit",
                "Introducing Amazon Elastic MapReduce",
                "Creating Similar Movies from One Million Ratings on EMR",
                "Partitioning",
                "Best Practices for Running on a Cluster",
                "Troubleshooting, and Managing Dependencies"
            ]
        },
        {
            "sectionName": "Machine Learning with Spark ML",
            "unitNames": [
                "Introducing MLLib",
                "[Activity] Using  MLLib to Produce Movie Recommendations",
                "Linear Regression with MLLib",
                "[Activity] Running a Linear Regression with Spark",
                "[Exercise] Predict Real Estate Values with Decision Trees in Spark",
                "Exercise Solution: Predicting Real Estate with Decision Trees in Spark"
            ]
        },
        {
            "sectionName": "Intro to Spark Streaming",
            "unitNames": [
                "The DStream API for Spark Streaming",
                "[Activity] Real-time Monitoring of the Most Popular Hashtags on Twitter",
                "Structured Streaming",
                "[Activity] Using Structured Streaming for real-time log analysis",
                "[Exercise] Windowed Operations with Structured Streaming",
                "Exercise Solution: Top URL's in a 30-second Window"
            ]
        },
        {
            "sectionName": "Intro to GraphX",
            "unitNames": [
                "GraphX, Pregel, and Breadth-First-Search with Pregel.",
                "Using the Pregel API with Spark GraphX",
                "[Activity] Superhero Degrees of Separation using GraphX"
            ]
        },
        {
            "sectionName": "You Made It! Where to Go from Here.",
            "unitNames": [
                "Learning More, and Career Tips",
                "Bonus Lecture: More courses to explore!"
            ]
        }
    ]
}